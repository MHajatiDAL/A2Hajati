summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be influential so gonna check them
cystfibr[c(16, 24), ]
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be influential so gonna check them
cystfibr[c(16, 24), ]
# Create a new dataset excluding observations 16 and 24
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# Fit the model again
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# Compare summary statistics
summary(model_filtered)
summary(model1)  # Compare with the original model
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be influential so gonna check them
cystfibr[c(16, 24), ]
# Create a new dataset excluding observations 16 and 24
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# Fit the model again
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# Compare summary statistics
summary(model_filtered)
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be have a lot leverage so gonna check them
cystfibr[c(16, 24), ]
# decided to delete them since 16 had short height and low weight
# compared to average and 24 was taller and heavier than average
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# doing the model again with the new data
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# getting the summary again
summary(model_filtered)
# in this one we have a higher R^2 meaning better fit
# a lower residual standard error again meaning better
# and a lower P value so our model is more statistically significant
# from this I can say that deleting 16 and 24 was the right call
# but i did this in a linear model, does that mean in other models
# 16 and 24 might actually be good or does this mean that
# 16 and 24 are bad across the board for all models?
model_step <- step(model_filtered, direction = "both")
summary(model_step)
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be have a lot leverage so gonna check them
cystfibr[c(16, 24), ]
# decided to delete them since 16 had short height and low weight
# compared to average and 24 was taller and heavier than average
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# doing the model again with the new data
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# getting the summary again
summary(model_filtered)
# in this one we have a higher R^2 meaning better fit
# a lower residual standard error again meaning better
# and a lower P value so our model is more statistically significant
# from this I can say that deleting 16 and 24 was the right call
# but i did this in a linear model, does that mean in other models
# 16 and 24 might actually be good or does this mean that
# 16 and 24 are bad across the board for all models?
# doing a stepwise selection
model_step <- step(model_filtered, direction = "both")
summary(model_step)
# looking at the summary the lowest AIC is for the:
# weight + bmp + fev1+ rv model
# I can see that in that model again theR^2 is higher than before
# the residual standard error is lower than before and the P value
# very small so it is very significant
# I can also look at individual parameter P values
# so we can see that weight has the lowest one meaning that
# weight and Pemax are highly positively correlated
# then fev1 and pemax are positively correlated
# then BMP and pemax are negatively correlated
# then the P value for rv is higher than 0.05, not sure why it would not exclude it
# gonna run a test for a model without rv since its p value is higher than 0.05
model_filtered <- lm(pemax ~ weight + bmp +fev1, data = cystfibr_filtered)
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be have a lot leverage so gonna check them
cystfibr[c(16, 24), ]
# decided to delete them since 16 had short height and low weight
# compared to average and 24 was taller and heavier than average
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# doing the model again with the new data
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# getting the summary again
summary(model_filtered)
# in this one we have a higher R^2 meaning better fit
# a lower residual standard error again meaning better
# and a lower P value so our model is more statistically significant
# from this I can say that deleting 16 and 24 was the right call
# but i did this in a linear model, does that mean in other models
# 16 and 24 might actually be good or does this mean that
# 16 and 24 are bad across the board for all models?
# doing a stepwise selection
model_step <- step(model_filtered, direction = "both")
summary(model_step)
# looking at the summary the lowest AIC is for the:
# weight + bmp + fev1+ rv model
# I can see that in that model again theR^2 is higher than before
# the residual standard error is lower than before and the P value
# very small so it is very significant
# I can also look at individual parameter P values
# so we can see that weight has the lowest one meaning that
# weight and Pemax are highly positively correlated
# then fev1 and pemax are positively correlated
# then BMP and pemax are negatively correlated
# then the P value for rv is higher than 0.05, not sure why it would not exclude it
# gonna run a test for a model without rv since its p value is higher than 0.05
model_filtered_1 <- lm(pemax ~ weight + bmp +fev1, data = cystfibr_filtered)
summary(model_filtered_1)
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be have a lot leverage so gonna check them
cystfibr[c(16, 24), ]
# decided to delete them since 16 had short height and low weight
# compared to average and 24 was taller and heavier than average
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# doing the model again with the new data
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# getting the summary again
summary(model_filtered)
# in this one we have a higher R^2 meaning better fit
# a lower residual standard error again meaning better
# and a lower P value so our model is more statistically significant
# from this I can say that deleting 16 and 24 was the right call
# but i did this in a linear model, does that mean in other models
# 16 and 24 might actually be good or does this mean that
# 16 and 24 are bad across the board for all models?
# doing a stepwise selection
model_step <- step(model_filtered, direction = "both")
summary(model_step)
# looking at the summary the lowest AIC is for the:
# weight + bmp + fev1+ rv model
# I can see that in that model again theR^2 is higher than before
# the residual standard error is lower than before and the P value
# very small so it is very significant
# I can also look at individual parameter P values
# so we can see that weight has the lowest one meaning that
# weight and Pemax are highly positively correlated
# then fev1 and pemax are positively correlated
# then BMP and pemax are negatively correlated
# then the P value for rv is higher than 0.05, not sure why it would not exclude it
# gonna run a test for a model without rv since its p value is higher than 0.05
model_filtered_2 <- lm(pemax ~ weight + bmp +fev1, data = cystfibr_filtered)
summary(model_filtered_2)
# okay so the model R^2, p value and residual standard error all went in the bad way
# so gonna keep rv in there.
# now we can check the residuals
par(mfrow = c(2,2))
plot(model_step)  # Check residual plots
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be have a lot leverage so gonna check them
cystfibr[c(16, 24), ]
# decided to delete them since 16 had short height and low weight
# compared to average and 24 was taller and heavier than average
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# doing the model again with the new data
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# getting the summary again
summary(model_filtered)
# in this one we have a higher R^2 meaning better fit
# a lower residual standard error again meaning better
# and a lower P value so our model is more statistically significant
# from this I can say that deleting 16 and 24 was the right call
# but i did this in a linear model, does that mean in other models
# 16 and 24 might actually be good or does this mean that
# 16 and 24 are bad across the board for all models?
# doing a stepwise selection
model_step <- step(model_filtered, direction = "both")
summary(model_step)
# looking at the summary the lowest AIC is for the:
# weight + bmp + fev1+ rv model
# I can see that in that model again theR^2 is higher than before
# the residual standard error is lower than before and the P value
# very small so it is very significant
# I can also look at individual parameter P values
# so we can see that weight has the lowest one meaning that
# weight and Pemax are highly positively correlated
# then fev1 and pemax are positively correlated
# then BMP and pemax are negatively correlated
# then the P value for rv is higher than 0.05, not sure why it would not exclude it
# gonna run a test for a model without rv since its p value is higher than 0.05
model_filtered_2 <- lm(pemax ~ weight + bmp +fev1, data = cystfibr_filtered)
summary(model_filtered_2)
# okay so the model R^2, p value and residual standard error all went in the bad way
# so gonna keep rv in there.
# now we can check the residuals
par(mfrow = c(2,2))
plot(model_step)  # Check residual plots
# I can still see some curvature maybe I should do a log transform
cystfibr_filtered$log_pemax <- log(cystfibr_filtered$pemax)
model_log <- lm(log_pemax ~ weight + bmp + fev1 + rv, data = cystfibr_filtered)
summary(model_log)
par(mfrow = c(2,2))
plot(model_log)
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be have a lot leverage so gonna check them
cystfibr[c(16, 24), ]
# decided to delete them since 16 had short height and low weight
# compared to average and 24 was taller and heavier than average
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# doing the model again with the new data
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# getting the summary again
summary(model_filtered)
# in this one we have a higher R^2 meaning better fit
# a lower residual standard error again meaning better
# and a lower P value so our model is more statistically significant
# from this I can say that deleting 16 and 24 was the right call
# but i did this in a linear model, does that mean in other models
# 16 and 24 might actually be good or does this mean that
# 16 and 24 are bad across the board for all models?
# doing a stepwise selection
model_step <- step(model_filtered, direction = "both")
summary(model_step)
# looking at the summary the lowest AIC is for the:
# weight + bmp + fev1+ rv model
# I can see that in that model again theR^2 is higher than before
# the residual standard error is lower than before and the P value
# very small so it is very significant
# I can also look at individual parameter P values
# so we can see that weight has the lowest one meaning that
# weight and Pemax are highly positively correlated
# then fev1 and pemax are positively correlated
# then BMP and pemax are negatively correlated
# then the P value for rv is higher than 0.05, not sure why it would not exclude it
# gonna run a test for a model without rv since its p value is higher than 0.05
model_filtered_2 <- lm(pemax ~ weight + bmp +fev1, data = cystfibr_filtered)
summary(model_filtered_2)
# okay so the model R^2, p value and residual standard error all went in the bad way
# so gonna keep rv in there.
# now we can check the residuals
par(mfrow = c(2,2))
plot(model_step)  # Check residual plots
# I can still see some curvature maybe I should do a log transform
cystfibr_filtered$log_pemax <- log(cystfibr_filtered$pemax)
model_log <- lm(log_pemax ~ weight + bmp + fev1 + rv, data = cystfibr_filtered)
summary(model_log)
par(mfrow = c(2,2))
plot(model_log)
# so after doing that we get a much lower residual std error
# but also a little bit lower R^2 and a little bit higher P value.
# gonna take out rv in this one too to see what happens
model_log_2 <- lm(log_pemax ~ weight + bmp + fev1, data = cystfibr_filtered)
summary(model_log_2)
knots<- c(10, 30, 50, 75)
f<- function(beta, x) {
# i changed the code here cause i did not like the syntax
which_piece<- cut(x, breaks = knots, labels = FALSE)
linear_pieces<- list()
# i changed the equations below to match the new ones found in the last set of equations
linear_pieces[[1]] <- function(x) beta[1] + beta[2] * (x - knots[1])
linear_pieces[[2]] <- function(x) (beta[1] + 20 * beta[2]) + beta[3] * (x - knots[2])
linear_pieces[[3]] <- function(x) (beta[1] + 20 * beta[2] + 20 * beta[3]) + beta[4] * (x - knots[3])
prediction<- sapply(
# again my syntax here is much more readable
seq_along(x),
function(i) linear_pieces[[which_piece[i]]](x[i])
)
return(prediction)
}
knots<- c(10, 30, 50, 75)
f<- function(beta, x) {
# i changed the code here cause i did not like the syntax
which_piece<- cut(x, breaks = knots, labels = FALSE)
linear_pieces<- list()
# i changed the equations below to match the new ones found in the last set of equations
linear_pieces[[1]] <- function(x) beta[1] + beta[2] * (x - knots[1])
linear_pieces[[2]] <- function(x) (beta[1] + 20 * beta[2]) + beta[3] * (x - knots[2])
linear_pieces[[3]] <- function(x) (beta[1] + 20 * beta[2] + 20 * beta[3]) + beta[4] * (x - knots[3])
prediction<- sapply(
# again my syntax here is much more readable
seq_along(x),
function(i) linear_pieces[[which_piece[i]]](x[i])
)
return(prediction)
}
# my sum of squares function
sum_of_squares <- function(beta) {
predicted <- f(beta, cystfibr$weight)
residuals <- cystfibr$pemax - predicted
return(sum(residuals^2))
}
#
beta_start <- c(1, 1, 1, 1)
# use nlminb, beta_start and to minimize the sum_of_squares function
result <- nlminb(start = beta_start, objective = sum_of_squares)
if( !requireNamespace("ISwR", quietly = TRUE) ) install.packages("ISwR")
library(ISwR)
data(cystfibr)
str(cystfibr)
summary(cystfibr)
# going with a linear to see if we are lucky
model1 <- lm(pemax ~ ., data = cystfibr)
summary(model1)
# from the summary i can see that sex, age, height, weight, FEV1, RV, FRC, TLC
# have high P values so fail the statistical test
# plot to see if I can get anything from it
par(mfrow = c(2, 2))
plot(model1)
# observations 16 and 24 seem to be have a lot leverage so gonna check them
cystfibr[c(16, 24), ]
# decided to delete them since 16 had short height and low weight
# compared to average and 24 was taller and heavier than average
cystfibr_filtered <- cystfibr[-c(16, 24), ]
# doing the model again with the new data
model_filtered <- lm(pemax ~ ., data = cystfibr_filtered)
# getting the summary again
summary(model_filtered)
# in this one we have a higher R^2 meaning better fit
# a lower residual standard error again meaning better
# and a lower P value so our model is more statistically significant
# from this I can say that deleting 16 and 24 was the right call
# but i did this in a linear model, does that mean in other models
# 16 and 24 might actually be good or does this mean that
# 16 and 24 are bad across the board for all models?
# doing a stepwise selection
model_step <- step(model_filtered, direction = "both")
summary(model_step)
# looking at the summary the lowest AIC is for the:
# weight + bmp + fev1+ rv model
# I can see that in that model again theR^2 is higher than before
# the residual standard error is lower than before and the P value
# very small so it is very significant
# I can also look at individual parameter P values
# so we can see that weight has the lowest one meaning that
# weight and Pemax are highly positively correlated
# then fev1 and pemax are positively correlated
# then BMP and pemax are negatively correlated
# then the P value for rv is higher than 0.05, not sure why it would not exclude it
# gonna run a test for a model without rv since its p value is higher than 0.05
model_filtered_2 <- lm(pemax ~ weight + bmp +fev1, data = cystfibr_filtered)
summary(model_filtered_2)
# okay so the model R^2, p value and residual standard error all went in the bad way
# so gonna keep rv in there.
# now we can check the residuals
par(mfrow = c(2,2))
plot(model_step)  # Check residual plots
# I can still see some curvature maybe I should do a log transform
cystfibr_filtered$log_pemax <- log(cystfibr_filtered$pemax)
model_log <- lm(log_pemax ~ weight + bmp + fev1 + rv, data = cystfibr_filtered)
summary(model_log)
par(mfrow = c(2,2))
plot(model_log)
# so after doing that we get a much lower residual std error
# but also a little bit lower R^2 and a little bit higher P value.
# but still the drop in residual std error is so much that I think its worth
# I think this is the best model and it tells us
# that weight, BMP, and FEV1 are highly correlated with pemax
# and you need RV to get a good fit of pemax
knots<- c(10, 30, 50, 75)
f<- function(beta, x) {
# i changed the code here cause i did not like the syntax
which_piece<- cut(x, breaks = knots, labels = FALSE)
linear_pieces<- list()
# i changed the equations below to match the new ones found in the last set of equations
linear_pieces[[1]] <- function(x) beta[1] + beta[2] * (x - knots[1])
linear_pieces[[2]] <- function(x) (beta[1] + 20 * beta[2]) + beta[3] * (x - knots[2])
linear_pieces[[3]] <- function(x) (beta[1] + 20 * beta[2] + 20 * beta[3]) + beta[4] * (x - knots[3])
prediction<- sapply(
# again my syntax here is much more readable
seq_along(x),
function(i) linear_pieces[[which_piece[i]]](x[i])
)
return(prediction)
}
# my sum of squares function
sum_of_squares <- function(beta) {
predicted <- f(beta, cystfibr$weight)
residuals <- cystfibr$pemax - predicted
return(sum(residuals^2))
}
#
beta_start <- c(1, 1, 1, 1)
# use nlminb, beta_start and to minimize the sum_of_squares function
result <- nlminb(start = beta_start, objective = sum_of_squares)
# get the best found paramters for beta
beta_best <- result$par
# now plot them
plot(cystfibr$weight, cystfibr$pemax, pch = 16, col = "blue", xlab = "Weight", ylab = "PEmax", main = "Piecewise Linear Spline Fit")
curve(f(beta_best, x), add = TRUE, col = "red", lwd = 2)
knots<- c(10, 30, 50, 75)
f<- function(beta, x) {
# i changed the code here cause i did not like the syntax
which_piece<- cut(x, breaks = knots, labels = FALSE)
linear_pieces<- list()
# i changed the equations below to match the new ones found in the last set of equations
linear_pieces[[1]] <- function(x) beta[1] + beta[2] * (x - knots[1])
linear_pieces[[2]] <- function(x) (beta[1] + 20 * beta[2]) + beta[3] * (x - knots[2])
linear_pieces[[3]] <- function(x) (beta[1] + 20 * beta[2] + 20 * beta[3]) + beta[4] * (x - knots[3])
prediction<- sapply(
# again my syntax here is much more readable
seq_along(x),
function(i) linear_pieces[[which_piece[i]]](x[i])
)
return(prediction)
}
# my sum of squares function
sum_of_squares <- function(beta) {
predicted <- f(beta, cystfibr$weight)
residuals <- cystfibr$pemax - predicted
return(sum(residuals^2))
}
#
beta_start <- c(10, 10, 10, 10)
# use nlminb, beta_start and to minimize the sum_of_squares function
result <- nlminb(start = beta_start, objective = sum_of_squares)
# get the best found paramters for beta
beta_best <- result$par
# now plot them
plot(cystfibr$weight, cystfibr$pemax, pch = 16, col = "blue", xlab = "Weight", ylab = "PEmax", main = "Piecewise Linear Spline Fit")
curve(f(beta_best, x), add = TRUE, col = "red", lwd = 2)
# yeah looking at the graph i can definitely see three different slopes and three different segments
# so the piecewise linear function actually works
